<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Title: Dataset for Question Answering (CN) [To be continued…]Date: 2024-08-14 13:21:39Tags: Dataset   © Wuyuhang, 2024. All rights reserved. This article is entirely the work of Wuyuhang from the Univ">
<meta property="og:type" content="article">
<meta property="og:title" content="Dataset-for-Question-Answering">
<meta property="og:url" content="http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/index.html">
<meta property="og:site_name" content="Yuhang&#39;s AI Journey">
<meta property="og:description" content="Title: Dataset for Question Answering (CN) [To be continued…]Date: 2024-08-14 13:21:39Tags: Dataset   © Wuyuhang, 2024. All rights reserved. This article is entirely the work of Wuyuhang from the Univ">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-08-14T13:47:20.000Z">
<meta property="article:modified_time" content="2024-08-14T15:48:25.135Z">
<meta property="article:author" content="YuhangWu">
<meta property="article:tag" content="Dataset">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/logo.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/logo.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.png">
        
      
    
    <!-- title -->
    <title>Dataset-for-Question-Answering</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 7.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/YuhangWuAI">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2024/08/14/RAG-End2end-Frame-and-Vector-DB-Summary/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2024/08/14/Dataset-for-Question-Answering-CN/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&text=Dataset-for-Question-Answering"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&is_video=false&description=Dataset-for-Question-Answering"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Dataset-for-Question-Answering&body=Check out this article: http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&name=Dataset-for-Question-Answering&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&t=Dataset-for-Question-Answering"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Overview-of-QA-Datasets"><span class="toc-number">1.</span> <span class="toc-text">Overview of QA Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Open-Domain-QA"><span class="toc-number">1.1.</span> <span class="toc-text">Open-Domain QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Table-Based-QA"><span class="toc-number">1.2.</span> <span class="toc-text">Table-Based QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-QA"><span class="toc-number">1.3.</span> <span class="toc-text">Knowledge Graph QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-Text-QA"><span class="toc-number">1.4.</span> <span class="toc-text">Knowledge Graph + Text QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Document-Based-QA"><span class="toc-number">1.5.</span> <span class="toc-text">Document-Based QA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Overview-of-QA-Datasets-1"><span class="toc-number">2.</span> <span class="toc-text">Overview of QA Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Open-Domain-QA-1"><span class="toc-number">2.1.</span> <span class="toc-text">Open-Domain QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Table-Based-QA-1"><span class="toc-number">2.2.</span> <span class="toc-text">Table-Based QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-QA-1"><span class="toc-number">2.3.</span> <span class="toc-text">Knowledge Graph QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-Text-QA-1"><span class="toc-number">2.4.</span> <span class="toc-text">Knowledge Graph + Text QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Document-Based-QA-1"><span class="toc-number">2.5.</span> <span class="toc-text">Document-Based QA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Detailed-QA-Dataset-Descriptions"><span class="toc-number">3.</span> <span class="toc-text">Detailed QA Dataset Descriptions</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Open-Domain-QA-Datasets"><span class="toc-number">3.1.</span> <span class="toc-text">Open-Domain QA Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HybridQA"><span class="toc-number">3.1.1.</span> <span class="toc-text">HybridQA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TAT-QA"><span class="toc-number">3.1.2.</span> <span class="toc-text">TAT-QA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FinQA"><span class="toc-number">3.1.3.</span> <span class="toc-text">FinQA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MultiHiertt"><span class="toc-number">3.1.4.</span> <span class="toc-text">MultiHiertt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HotpotQA"><span class="toc-number">3.1.5.</span> <span class="toc-text">HotpotQA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FEVER"><span class="toc-number">3.1.6.</span> <span class="toc-text">FEVER</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Table-Based-Question-Answering-Datasets"><span class="toc-number">3.2.</span> <span class="toc-text">Table-Based Question Answering Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#WikiTableQuestions-WTQ"><span class="toc-number">3.2.1.</span> <span class="toc-text">WikiTableQuestions (WTQ)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AIT-QA"><span class="toc-number">3.2.2.</span> <span class="toc-text">AIT-QA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TabFact"><span class="toc-number">3.2.3.</span> <span class="toc-text">TabFact</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SQA-SequentialQA"><span class="toc-number">3.2.4.</span> <span class="toc-text">SQA (SequentialQA)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#To-be-continued%E2%80%A6"><span class="toc-number">4.</span> <span class="toc-text">(To be continued…)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Acknowledgment"><span class="toc-number">4.1.</span> <span class="toc-text">Acknowledgment</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">4.2.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        Dataset-for-Question-Answering
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">YuhangWu</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2024-08-14T13:47:20.000Z" class="dt-published" itemprop="datePublished">2024-08-14</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/Dataset/" rel="tag">Dataset</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p><strong>Title:</strong> Dataset for Question Answering (CN) [To be continued…]<br><strong>Date:</strong> 2024-08-14 13:21:39<br><strong>Tags:</strong> Dataset  </p>
<p>© Wuyuhang, 2024. All rights reserved. This article is entirely the work of Wuyuhang from the University of Manchester. It may not be reproduced, distributed, or used without explicit permission from the author. For inquiries, please contact me at yuhang.wu-4 [at] postgrad.manchester.ac.uk.</p>
<h1 id="Overview-of-QA-Datasets"><a href="#Overview-of-QA-Datasets" class="headerlink" title="Overview of QA Datasets"></a>Overview of QA Datasets</h1><p>Question Answering (QA) systems are a core area of research in natural language processing, aimed at extracting precise answers from various information sources. To meet diverse research needs and application scenarios, various QA datasets have emerged, systematically classified according to data format and task characteristics. This overview introduces several important QA datasets, covering a range of data types and task requirements. These datasets provide rich resources for testing and training, driving performance improvements and technological advancements in QA systems across different information formats.</p>
<h2 id="Open-Domain-QA"><a href="#Open-Domain-QA" class="headerlink" title="Open-Domain QA"></a>Open-Domain QA</h2><ul>
<li><strong><a target="_blank" rel="noopener" href="https://hybridqa.github.io/">HybridQA</a></strong>: Each question is aligned with a Wikipedia table and multiple paragraphs, linking table cells to paragraphs.</li>
<li><strong><a target="_blank" rel="noopener" href="https://ott-qa.github.io/">OTT-QA</a></strong>: Based on the HybridQA dataset, combining text and table evidence to create an open-domain QA benchmark.</li>
<li><strong><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.12011">NQ-Table</a></strong>: An open-domain QA dataset that combines table and text evidence.</li>
<li><strong><a target="_blank" rel="noopener" href="https://nextplusplus.github.io/TAT-QA/">TAT-QA</a></strong>: Similar to FinQA but includes both arithmetic questions and range questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://finqasite.github.io/">FinQA</a></strong>: A financial report dataset based on HybridQA, including only arithmetic questions (excluding range questions).</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/MultiHiertt">MultiHiertt</a></strong>: A numerical reasoning dataset with hierarchical tables and text.</li>
<li><strong><a target="_blank" rel="noopener" href="https://nlp.cs.washington.edu/triviaqa/">TriviaQA</a></strong>: An open-domain QA dataset with multiple domains, providing rich evidence paragraphs for answering questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://ai.google.com/research/NaturalQuestions">Natural Questions</a></strong>: Provides natural language questions and their corresponding Wikipedia paragraphs, supporting open-domain QA research.</li>
<li><strong><a target="_blank" rel="noopener" href="https://hotpotqa.github.io/">HotpotQA</a></strong>: Provides multi-hop reasoning questions and answers, requiring information retrieval from multiple documents to answer.</li>
<li><strong><a target="_blank" rel="noopener" href="https://fever.ai/">FEVER</a></strong>: Primarily used for fact verification tasks, offering news articles and corresponding truth judgment questions.</li>
</ul>
<h2 id="Table-Based-QA"><a href="#Table-Based-QA" class="headerlink" title="Table-Based QA"></a>Table-Based QA</h2><ul>
<li><strong><a target="_blank" rel="noopener" href="https://ppasupat.github.io/WikiTableQuestions/">WikiTableQuestions (WTQ)</a></strong>: Contains 22,033 question-answer pairs with 2,108 tables; manually annotated questions and answers.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/salesforce/WikiSQL">WikiSQL</a></strong>: SQL-annotated tables from Wikipedia, including 81,000 questions and 24,000 tables.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/IBM/AITQA">AIT-QA</a></strong>: Involves hierarchical tables with 116 tables about U.S. flights and 515 questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2108.06712v3">HiTab</a></strong>: A dataset for hierarchical tables.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/google-research/tapas">TAPAS</a></strong>: A table-based QA dataset combining SQL queries and natural language questions, covering various table formats.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/wtmo/TabFact">TabFact</a></strong>: A fact verification dataset with tables, providing a large number of tables and corresponding fact-checking questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/ABSA-HKUST/TableQA">TableQA</a></strong>: Covers QA tasks across various table structures, focusing on extracting information from tables.</li>
<li><strong><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=54253">SQA</a></strong>: Focuses on QA tasks involving structured data through SQL queries.</li>
</ul>
<h2 id="Knowledge-Graph-QA"><a href="#Knowledge-Graph-QA" class="headerlink" title="Knowledge Graph QA"></a>Knowledge Graph QA</h2><ul>
<li><strong>MetaQA (2018)</strong>: A knowledge graph QA dataset.</li>
<li><strong>GRAPHQ (2016)</strong>: A knowledge graph QA dataset.</li>
<li><strong>WebQSP (2016)</strong>: A QA dataset based on Freebase.</li>
<li><strong>CWQ (2018)</strong>: An extended dataset based on WebQSP, using SPARQL query annotations to study semantic parsing.</li>
<li><strong>LC-QuAD (2017)</strong> and <strong>LC-QuAD 2.0 (2019)</strong>: Knowledge graph datasets based on Wikidata and DBpedia, including 30,000 questions with SPARQL query annotations.</li>
<li><strong>GrailQA (2021)</strong>: A knowledge graph QA dataset based on Freebase, with 64,000 questions and query annotations.</li>
<li><strong>KQA Pro (2022)</strong>: A dataset with NL questions and SPARQL annotations, including knowledge graphs from FB15k-237 and aligned Wikidata entities and 3,000 additional entities.</li>
<li><strong>Freebase QA (2014)</strong>: An early QA dataset using the Freebase knowledge graph, providing a large number of QA pairs about the knowledge graph.</li>
</ul>
<h2 id="Knowledge-Graph-Text-QA"><a href="#Knowledge-Graph-Text-QA" class="headerlink" title="Knowledge Graph + Text QA"></a>Knowledge Graph + Text QA</h2><ul>
<li>Evaluates open-domain text QA datasets: TriviaQA (2017), WebQuestion (2013), CWQ (2018), WebQAP (2016), using knowledge graphs like WordNet, Freebase, ConceptNet.</li>
<li><strong>WebQuestion (2013)</strong>: Contains natural language questions targeting Freebase and corresponding answers, widely used in knowledge graph and text QA research.</li>
<li><strong>ComplexWebQuestions (CWQ) (2018)</strong>: Extends WebQuestion with complex SPARQL queries to test knowledge graph QA capabilities.</li>
</ul>
<h2 id="Document-Based-QA"><a href="#Document-Based-QA" class="headerlink" title="Document-Based QA"></a>Document-Based QA</h2><ul>
<li><strong>SQuAD (2018)</strong>: A document QA dataset providing a large-scale collection of paragraphs and question pairs for assessing model comprehension. <a target="_blank" rel="noopener" href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a></li>
<li><strong>TrivialQA (2017)</strong>: A document QA dataset focusing on simple questions, mainly used for baseline model evaluation.</li>
<li><strong>Natural Questions (NQ) (2019)</strong>: Provides natural language questions and their corresponding Wikipedia paragraphs, supporting open-domain QA research. <a target="_blank" rel="noopener" href="https://ai.google.com/research/NaturalQuestions">Natural Questions</a></li>
<li><strong>SearchQA (2017)</strong>: A search engine-based QA dataset, including questions and answers extracted from web search results.</li>
<li><strong>DocVQA (2020)</strong>: A document QA dataset focusing on extracting information from complex documents, including scanned documents and tables.</li>
<li><strong>FEVEROUS (2020)</strong>: A fact verification QA dataset, expanding the FEVER dataset with additional documents and verification tasks.</li>
<li><strong>HotpotQA (2018)</strong>: Provides multi-hop reasoning questions and answers, requiring information retrieval from multiple documents to answer. <a target="_blank" rel="noopener" href="https://hotpotqa.github.io/">HotpotQA</a></li>
</ul>
<p>Sure, here is the refined text in natural, academic English and formatted in Markdown:</p>
<hr>
<p><strong>Title:</strong> Dataset for Question Answering (CN) [To be continued…]<br><strong>Date:</strong> 2024-08-14 13:21:39<br><strong>Tags:</strong> Dataset  </p>
<p>© Wuyuhang, 2024. All rights reserved. This article is entirely the work of Wuyuhang from the University of Manchester. It may not be reproduced, distributed, or used without explicit permission from the author. For inquiries, please contact me at yuhang.wu-4 [at] postgrad.manchester.ac.uk.</p>
<h1 id="Overview-of-QA-Datasets-1"><a href="#Overview-of-QA-Datasets-1" class="headerlink" title="Overview of QA Datasets"></a>Overview of QA Datasets</h1><p>Question Answering (QA) systems are a core area of research in natural language processing, aimed at extracting precise answers from various information sources. To meet diverse research needs and application scenarios, various QA datasets have emerged, systematically classified according to data format and task characteristics. This overview introduces several important QA datasets, covering a range of data types and task requirements. These datasets provide rich resources for testing and training, driving performance improvements and technological advancements in QA systems across different information formats.</p>
<h2 id="Open-Domain-QA-1"><a href="#Open-Domain-QA-1" class="headerlink" title="Open-Domain QA"></a>Open-Domain QA</h2><ul>
<li><strong><a target="_blank" rel="noopener" href="https://hybridqa.github.io/">HybridQA</a></strong>: Each question is aligned with a Wikipedia table and multiple paragraphs, linking table cells to paragraphs.</li>
<li><strong><a target="_blank" rel="noopener" href="https://ott-qa.github.io/">OTT-QA</a></strong>: Based on the HybridQA dataset, combining text and table evidence to create an open-domain QA benchmark.</li>
<li><strong><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.12011">NQ-Table</a></strong>: An open-domain QA dataset that combines table and text evidence.</li>
<li><strong><a target="_blank" rel="noopener" href="https://nextplusplus.github.io/TAT-QA/">TAT-QA</a></strong>: Similar to FinQA but includes both arithmetic questions and range questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://finqasite.github.io/">FinQA</a></strong>: A financial report dataset based on HybridQA, including only arithmetic questions (excluding range questions).</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/MultiHiertt">MultiHiertt</a></strong>: A numerical reasoning dataset with hierarchical tables and text.</li>
<li><strong><a target="_blank" rel="noopener" href="https://nlp.cs.washington.edu/triviaqa/">TriviaQA</a></strong>: An open-domain QA dataset with multiple domains, providing rich evidence paragraphs for answering questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://ai.google.com/research/NaturalQuestions">Natural Questions</a></strong>: Provides natural language questions and their corresponding Wikipedia paragraphs, supporting open-domain QA research.</li>
<li><strong><a target="_blank" rel="noopener" href="https://hotpotqa.github.io/">HotpotQA</a></strong>: Provides multi-hop reasoning questions and answers, requiring information retrieval from multiple documents to answer.</li>
<li><strong><a target="_blank" rel="noopener" href="https://fever.ai/">FEVER</a></strong>: Primarily used for fact verification tasks, offering news articles and corresponding truth judgment questions.</li>
</ul>
<h2 id="Table-Based-QA-1"><a href="#Table-Based-QA-1" class="headerlink" title="Table-Based QA"></a>Table-Based QA</h2><ul>
<li><strong><a target="_blank" rel="noopener" href="https://ppasupat.github.io/WikiTableQuestions/">WikiTableQuestions (WTQ)</a></strong>: Contains 22,033 question-answer pairs with 2,108 tables; manually annotated questions and answers.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/salesforce/WikiSQL">WikiSQL</a></strong>: SQL-annotated tables from Wikipedia, including 81,000 questions and 24,000 tables.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/IBM/AITQA">AIT-QA</a></strong>: Involves hierarchical tables with 116 tables about U.S. flights and 515 questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2108.06712v3">HiTab</a></strong>: A dataset for hierarchical tables.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/google-research/tapas">TAPAS</a></strong>: A table-based QA dataset combining SQL queries and natural language questions, covering various table formats.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/wtmo/TabFact">TabFact</a></strong>: A fact verification dataset with tables, providing a large number of tables and corresponding fact-checking questions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/ABSA-HKUST/TableQA">TableQA</a></strong>: Covers QA tasks across various table structures, focusing on extracting information from tables.</li>
<li><strong><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=54253">SQA</a></strong>: Focuses on QA tasks involving structured data through SQL queries.</li>
</ul>
<h2 id="Knowledge-Graph-QA-1"><a href="#Knowledge-Graph-QA-1" class="headerlink" title="Knowledge Graph QA"></a>Knowledge Graph QA</h2><ul>
<li><strong>MetaQA (2018)</strong>: A knowledge graph QA dataset.</li>
<li><strong>GRAPHQ (2016)</strong>: A knowledge graph QA dataset.</li>
<li><strong>WebQSP (2016)</strong>: A QA dataset based on Freebase.</li>
<li><strong>CWQ (2018)</strong>: An extended dataset based on WebQSP, using SPARQL query annotations to study semantic parsing.</li>
<li><strong>LC-QuAD (2017)</strong> and <strong>LC-QuAD 2.0 (2019)</strong>: Knowledge graph datasets based on Wikidata and DBpedia, including 30,000 questions with SPARQL query annotations.</li>
<li><strong>GrailQA (2021)</strong>: A knowledge graph QA dataset based on Freebase, with 64,000 questions and query annotations.</li>
<li><strong>KQA Pro (2022)</strong>: A dataset with NL questions and SPARQL annotations, including knowledge graphs from FB15k-237 and aligned Wikidata entities and 3,000 additional entities.</li>
<li><strong>Freebase QA (2014)</strong>: An early QA dataset using the Freebase knowledge graph, providing a large number of QA pairs about the knowledge graph.</li>
</ul>
<h2 id="Knowledge-Graph-Text-QA-1"><a href="#Knowledge-Graph-Text-QA-1" class="headerlink" title="Knowledge Graph + Text QA"></a>Knowledge Graph + Text QA</h2><ul>
<li>Evaluates open-domain text QA datasets: TriviaQA (2017), WebQuestion (2013), CWQ (2018), WebQAP (2016), using knowledge graphs like WordNet, Freebase, ConceptNet.</li>
<li><strong>WebQuestion (2013)</strong>: Contains natural language questions targeting Freebase and corresponding answers, widely used in knowledge graph and text QA research.</li>
<li><strong>ComplexWebQuestions (CWQ) (2018)</strong>: Extends WebQuestion with complex SPARQL queries to test knowledge graph QA capabilities.</li>
</ul>
<h2 id="Document-Based-QA-1"><a href="#Document-Based-QA-1" class="headerlink" title="Document-Based QA"></a>Document-Based QA</h2><ul>
<li><strong><a target="_blank" rel="noopener" href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a></strong>: A document QA dataset providing a large-scale collection of paragraphs and question pairs for assessing model comprehension. </li>
<li><strong>TrivialQA (2017)</strong>: A document QA dataset focusing on simple questions, mainly used for baseline model evaluation.</li>
<li><strong><a target="_blank" rel="noopener" href="https://ai.google.com/research/NaturalQuestions">Natural Questions</a></strong>: Provides natural language questions and their corresponding Wikipedia paragraphs, supporting open-domain QA research. </li>
<li><strong>SearchQA (2017)</strong>: A search engine-based QA dataset, including questions and answers extracted from web search results.</li>
<li><strong>DocVQA (2020)</strong>: A document QA dataset focusing on extracting information from complex documents, including scanned documents and tables.</li>
<li><strong>FEVEROUS (2020)</strong>: A fact verification QA dataset, expanding the FEVER dataset with additional documents and verification tasks.</li>
<li><strong><a target="_blank" rel="noopener" href="https://hotpotqa.github.io/">HotpotQA</a></strong>: Provides multi-hop reasoning questions and answers, requiring information retrieval from multiple documents to answer.</li>
</ul>
<h1 id="Detailed-QA-Dataset-Descriptions"><a href="#Detailed-QA-Dataset-Descriptions" class="headerlink" title="Detailed QA Dataset Descriptions"></a>Detailed QA Dataset Descriptions</h1><h2 id="Open-Domain-QA-Datasets"><a href="#Open-Domain-QA-Datasets" class="headerlink" title="Open-Domain QA Datasets"></a>Open-Domain QA Datasets</h2><h3 id="HybridQA"><a href="#HybridQA" class="headerlink" title="HybridQA"></a><a target="_blank" rel="noopener" href="https://hybridqa.github.io/">HybridQA</a></h3><p><strong>Introduction</strong>: <a target="_blank" rel="noopener" href="https://hybridqa.github.io/">HybridQA</a>, proposed by Chen et al. in “HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data,” addresses the challenge of reasoning over heterogeneous information. Unlike existing QA datasets that primarily focus on homogeneous information, HybridQA requires reasoning over both tables and text. Each question is associated with a Wikipedia table and multiple paragraphs related to the table’s entities. The questions are designed to require synthesizing both types of information, making the absence of either type insufficient for answering. Experiments show that while baseline models using only tables or text perform poorly, a hybrid model that integrates both types achieves significantly better results, though still trailing behind human performance. This dataset serves as a challenging benchmark for studying QA tasks involving heterogeneous information.</p>
<p><strong>Dataset and Code</strong>: Available publicly at <a target="_blank" rel="noopener" href="https://github.com/wenhuchen/HybridQA">GitHub - HybridQA</a>.</p>
<h3 id="TAT-QA"><a href="#TAT-QA" class="headerlink" title="TAT-QA"></a>TAT-QA</h3><p><strong>Introduction</strong>: TAT-QA, introduced by Zhu et al. in “TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,” is a large-scale QA dataset aimed at advancing research on complex financial data that combines tables and text. It involves questions requiring numerical reasoning over financial reports.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Context includes a semi-structured table and at least two related paragraphs describing or supplementing the table content.</li>
<li>Questions are generated by experts with rich financial knowledge, most being real-world application questions.</li>
<li>Answers vary in format, including single span, multiple spans, and free-form responses.</li>
<li>Answering often requires diverse numerical reasoning abilities such as addition, subtraction, multiplication, division, counting, comparison, sorting, and combinations thereof.</li>
<li>Along with real answers, the dataset includes the corresponding reasoning processes and scales, when applicable.</li>
</ul>
<p><strong>Size</strong>: TAT-QA contains 16,552 questions based on 2,757 mixed-context financial reports.</p>
<h3 id="FinQA"><a href="#FinQA" class="headerlink" title="FinQA"></a>FinQA</h3><p><strong>Introduction</strong>: FinQA, proposed by Chen et al. in “FinQA: A Dataset of Numerical Reasoning over Financial Data,” focuses on deep QA over financial data, aiming to automate the analysis of extensive financial documents. Compared to general domain tasks, the financial domain involves complex numerical reasoning and understanding of heterogeneous representations.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Provides QA pairs created by financial experts, with annotated gold reasoning programs to ensure full interpretability.</li>
<li>Introduces baseline models and conducts extensive experiments, showing that popular large pre-trained models significantly lag behind experts in acquiring financial knowledge and performing complex multi-step numerical reasoning.</li>
<li>Dataset and code are available at <a target="_blank" rel="noopener" href="https://github.com/czyssrs/FinQA">GitHub - FinQA</a>.</li>
</ul>
<h3 id="MultiHiertt"><a href="#MultiHiertt" class="headerlink" title="MultiHiertt"></a><a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/MultiHiertt">MultiHiertt</a></h3><p><strong>Introduction</strong>: <a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/MultiHiertt">MultiHiertt</a>, introduced by Wang et al. in “MultiHiertt: A Multi-Modal Dataset for Hierarchical Table-Based Numerical Reasoning,” provides a dataset specifically for numerical reasoning over hierarchical tables. Unlike other table-based datasets that focus on flat or moderately complex tables, <a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/MultiHiertt">MultiHiertt</a> features hierarchical tables that reflect the multi-level nature of real-world financial documents.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Contains hierarchical tables with multiple levels of nesting, reflecting complex financial data structures.</li>
<li>Focuses on multi-modal reasoning, requiring combining information from different hierarchical levels and types.</li>
</ul>
<p><strong>Size</strong>: <a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/MultiHiertt">MultiHiertt</a> includes a range of hierarchical tables and associated questions to test different levels of numerical reasoning.</p>
<p>Certainly! Here’s the refined version of the content in academic English with Markdown formatting:</p>
<hr>
<h3 id="HotpotQA"><a href="#HotpotQA" class="headerlink" title="HotpotQA"></a><a target="_blank" rel="noopener" href="https://hotpotqa.github.io/">HotpotQA</a></h3><p><strong>Introduction</strong>: <a target="_blank" rel="noopener" href="https://hotpotqa.github.io/">HotpotQA</a> was introduced by Yang et al. in “<a target="_blank" rel="noopener" href="https://hotpotqa.github.io/">HotpotQA</a>: A Dataset for Diverse, Explainable Multi-hop Question Answering”. This dataset, based on English Wikipedia, includes approximately 113,000 crowd-sourced questions that require information from two introductory paragraphs of Wikipedia articles to answer.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Covers various reasoning strategies, including questions involving missing entities, intersection questions (e.g., “What satisfies both attribute A and attribute B?”), and comparison questions.</li>
<li>Provides ten paragraphs, including golden paragraphs. In the open-domain full Wikipedia setting, models are given only the question and the entire Wikipedia.</li>
<li>Evaluation metrics include answer accuracy (measured by Exact Match (EM) and word F1 score) and explainability (assessing the alignment of predicted supporting sentences with human-annotated sentences).</li>
</ul>
<h3 id="FEVER"><a href="#FEVER" class="headerlink" title="FEVER"></a><a target="_blank" rel="noopener" href="https://fever.ai/">FEVER</a></h3><p><strong>Introduction</strong>: FEVER (Fact Extraction and VERification) was proposed by Thorne et al. in “FEVER: a large-scale dataset for Fact Extraction and VERification”. This dataset is used for verifying facts from textual sources and includes 185,445 statements generated by altering sentences from Wikipedia, which are subsequently verified.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Statements are classified as “support”, “refute”, or “not enough information”.</li>
<li>For the first two categories, annotators record the sentences required to make a judgment.</li>
<li>Developed a pipeline approach and compared it with well-designed predictors, demonstrating that FEVER is a challenging test platform that advances research in statement verification from textual sources.</li>
</ul>
<p><strong>Dataset and Code</strong>: <a target="_blank" rel="noopener" href="https://fever.ai/">FEVER</a></p>
<h2 id="Table-Based-Question-Answering-Datasets"><a href="#Table-Based-Question-Answering-Datasets" class="headerlink" title="Table-Based Question Answering Datasets"></a>Table-Based Question Answering Datasets</h2><h3 id="WikiTableQuestions-WTQ"><a href="#WikiTableQuestions-WTQ" class="headerlink" title="WikiTableQuestions (WTQ)"></a><a target="_blank" rel="noopener" href="https://ppasupat.github.io/WikiTableQuestions/">WikiTableQuestions (WTQ)</a></h3><p><strong>Introduction</strong>: <a target="_blank" rel="noopener" href="https://ppasupat.github.io/WikiTableQuestions/">WikiTableQuestions (WTQ)</a>, introduced by Pasupat et al. in “Compositional Semantic Parsing on Semi-Structured Tables”, is based on HTML tables and includes 22,033 question-answer pairs. The questions were crafted by Amazon Mechanical Turk workers, and the tables were sourced from Wikipedia, each containing at least 8 rows and 5 columns.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Questions are manually crafted by users rather than through predefined templates, showcasing significant linguistic variability.</li>
<li>Compared to previous knowledge base datasets, it covers nearly 4,000 unique column headers and involves more relationships than closed-domain datasets.</li>
<li>Questions span a wide range of domains and require various operations, including table retrieval, aggregation, superlatives (e.g., maximum, minimum), arithmetic calculations, joining, and merging.</li>
</ul>
<h3 id="AIT-QA"><a href="#AIT-QA" class="headerlink" title="AIT-QA"></a><a target="_blank" rel="noopener" href="https://github.com/IBM/AITQA">AIT-QA</a></h3><p><strong>Introduction</strong>: <a target="_blank" rel="noopener" href="https://github.com/IBM/AITQA">AIT-QA</a> (Airline Industry Table QA), proposed by Katsis et al. in “AIT-QA: Question Answering Dataset over Complex Tables in the Airline Industry”, is a domain-specific table-based question answering dataset. It includes 515 questions crafted by human annotators based on 116 tables extracted from the annual reports of major airlines from the SEC filings (2017-2019). The dataset also contains annotations on the nature of questions, highlighting those requiring hierarchical headers, domain-specific terminology, and synonym variations.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>The table layouts are more complex, presenting greater challenges compared to traditional table-based QA datasets.</li>
<li>Includes annotations indicating questions that require hierarchical headers, domain-specific terminology, and synonym variations.</li>
</ul>
<p><strong>Dataset and Code</strong>: Available publicly: <a target="_blank" rel="noopener" href="https://github.com/IBM/AITQA">GitHub - AIT-QA</a></p>
<h3 id="TabFact"><a href="#TabFact" class="headerlink" title="TabFact"></a><a target="_blank" rel="noopener" href="https://tabfact.github.io/">TabFact</a></h3><p><strong>Introduction</strong>: <a target="_blank" rel="noopener" href="https://tabfact.github.io/">TabFact</a>, introduced by Chen et al. in “TabFact: A Large-scale Dataset for Table-based Fact Verification”, is a large-scale dataset containing 117,854 manually annotated statements involving 16,573 Wikipedia tables. The relationships in these statements are classified as “entailed” or “refuted”. <a target="_blank" rel="noopener" href="https://tabfact.github.io/">TabFact</a> is the first dataset designed to evaluate language reasoning over structured data, involving both symbolic and linguistic reasoning skills.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Provides a large-scale dataset for fact verification based on tables.</li>
<li>Relationship classification as “entailed” or “refuted”, challenging the model’s language reasoning and structured data processing capabilities.</li>
</ul>
<p><strong>Dataset and Code</strong>: Available publicly: <a target="_blank" rel="noopener" href="https://tabfact.github.io/">TabFact</a></p>
<h3 id="SQA-SequentialQA"><a href="#SQA-SequentialQA" class="headerlink" title="SQA (SequentialQA)"></a><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=54253">SQA</a> (SequentialQA)</h3><p><strong>Introduction</strong>: <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=54253">SQA</a>, proposed by Iyyer et al. in “Search-based Neural Structured Learning for Sequential Question Answering”, explores the task of answering a sequence of related questions over HTML tables. The dataset comprises 6,066 sequences, totaling 17,553 questions.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Focuses on answering a series of related questions within HTML tables.</li>
<li>Provides a rich set of sequential questions, covering various problem orders and interrelationships.</li>
</ul>
<p><strong>Dataset and Code</strong>: Available publicly: <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=54253">SQA</a></p>
<h1 id="To-be-continued…"><a href="#To-be-continued…" class="headerlink" title="(To be continued…)"></a>(To be continued…)</h1><h2 id="Acknowledgment"><a href="#Acknowledgment" class="headerlink" title="Acknowledgment"></a>Acknowledgment</h2><p>I would like to express my sincere gratitude to my advisor, Jiaoyan Chen, for his invaluable guidance throughout this research. His generous sharing of datasets and resources has been instrumental in the development of this study.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Chen, W., Zha, H., Chen, Z., Xiong, W., Wang, H. and Wang, W., 2020. Hybridqa: A dataset of multi-hop question answering over tabular and textual data. arXiv preprint arXiv:2004.07347.</li>
<li>Chen, W., Chang, M.W., Schlinger, E., Wang, W. and Cohen, W.W., 2020. Open question answering over tables and text. arXiv preprint arXiv:2010.10439.</li>
<li>Herzig, J., Müller, T., Krichene, S. and Eisenschlos, J.M., 2021. Open domain question answering over tables via dense retrieval. arXiv preprint arXiv:2103.12011.</li>
<li>Chen, Z., Chen, W., Smiley, C., Shah, S., Borova, I., Langdon, D., Moussa, R., Beane, M., Huang, T.H., Routledge, B. and Wang, W.Y., 2021. Finqa: A dataset of numerical reasoning over financial data. arXiv preprint arXiv:2109.00122.</li>
<li>Zhao, Y., Li, Y., Li, C. and Zhang, R., 2022. MultiHiertt: Numerical reasoning over multi hierarchical tabular and textual data. arXiv preprint arXiv:2206.01347.</li>
<li>Qi, P., Lin, X., Mehr, L., Wang, Z. and Manning, C.D., 2019. Answering complex open-domain questions through iterative query generation. arXiv preprint arXiv:1910.07000.</li>
<li>Joshi, M., Choi, E., Weld, D.S. and Zettlemoyer, L., 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551.</li>
<li>Thorne, J., Vlachos, A., Christodoulopoulos, C. and Mittal, A., 2018. FEVER: a large-scale dataset for fact extraction and VERification. arXiv preprint arXiv:1803.05355.</li>
<li>Pasupat, P. and Liang, P., 2015. Compositional semantic parsing on semi-structured tables. arXiv preprint arXiv:1508.00305.</li>
<li>Katsis, Y., Chemmengath, S., Kumar, V., Bharadwaj, S., Canim, M., Glass, M., Gliozzo, A., Pan, F., Sen, J., Sankaranarayanan, K. and Chakrabarti, S., 2021. AIT-QA: Question answering dataset over complex tables in the airline industry. arXiv preprint arXiv:2106.12944.</li>
<li>Cheng, Z., Dong, H., Wang, Z., Jia, R., Guo, J., Gao, Y., Han, S., Lou, J.G. and Zhang, D., 2021. Hitab: A hierarchical table dataset for question answering and natural language generation. arXiv preprint arXiv:2108.06712.</li>
<li>Chen, W., Wang, H., Chen, J., Zhang, Y., Wang, H., Li, S., Zhou, X. and Wang, W.Y., 2019. Tabfact: A large-scale dataset for table-based fact verification. arXiv preprint arXiv:1909.02164.</li>
</ol>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a target="_blank" rel="noopener" href="https://github.com/YuhangWuAI">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Overview-of-QA-Datasets"><span class="toc-number">1.</span> <span class="toc-text">Overview of QA Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Open-Domain-QA"><span class="toc-number">1.1.</span> <span class="toc-text">Open-Domain QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Table-Based-QA"><span class="toc-number">1.2.</span> <span class="toc-text">Table-Based QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-QA"><span class="toc-number">1.3.</span> <span class="toc-text">Knowledge Graph QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-Text-QA"><span class="toc-number">1.4.</span> <span class="toc-text">Knowledge Graph + Text QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Document-Based-QA"><span class="toc-number">1.5.</span> <span class="toc-text">Document-Based QA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Overview-of-QA-Datasets-1"><span class="toc-number">2.</span> <span class="toc-text">Overview of QA Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Open-Domain-QA-1"><span class="toc-number">2.1.</span> <span class="toc-text">Open-Domain QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Table-Based-QA-1"><span class="toc-number">2.2.</span> <span class="toc-text">Table-Based QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-QA-1"><span class="toc-number">2.3.</span> <span class="toc-text">Knowledge Graph QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-Graph-Text-QA-1"><span class="toc-number">2.4.</span> <span class="toc-text">Knowledge Graph + Text QA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Document-Based-QA-1"><span class="toc-number">2.5.</span> <span class="toc-text">Document-Based QA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Detailed-QA-Dataset-Descriptions"><span class="toc-number">3.</span> <span class="toc-text">Detailed QA Dataset Descriptions</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Open-Domain-QA-Datasets"><span class="toc-number">3.1.</span> <span class="toc-text">Open-Domain QA Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HybridQA"><span class="toc-number">3.1.1.</span> <span class="toc-text">HybridQA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TAT-QA"><span class="toc-number">3.1.2.</span> <span class="toc-text">TAT-QA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FinQA"><span class="toc-number">3.1.3.</span> <span class="toc-text">FinQA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MultiHiertt"><span class="toc-number">3.1.4.</span> <span class="toc-text">MultiHiertt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HotpotQA"><span class="toc-number">3.1.5.</span> <span class="toc-text">HotpotQA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FEVER"><span class="toc-number">3.1.6.</span> <span class="toc-text">FEVER</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Table-Based-Question-Answering-Datasets"><span class="toc-number">3.2.</span> <span class="toc-text">Table-Based Question Answering Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#WikiTableQuestions-WTQ"><span class="toc-number">3.2.1.</span> <span class="toc-text">WikiTableQuestions (WTQ)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AIT-QA"><span class="toc-number">3.2.2.</span> <span class="toc-text">AIT-QA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TabFact"><span class="toc-number">3.2.3.</span> <span class="toc-text">TabFact</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SQA-SequentialQA"><span class="toc-number">3.2.4.</span> <span class="toc-text">SQA (SequentialQA)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#To-be-continued%E2%80%A6"><span class="toc-number">4.</span> <span class="toc-text">(To be continued…)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Acknowledgment"><span class="toc-number">4.1.</span> <span class="toc-text">Acknowledgment</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">4.2.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&text=Dataset-for-Question-Answering"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&is_video=false&description=Dataset-for-Question-Answering"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Dataset-for-Question-Answering&body=Check out this article: http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&title=Dataset-for-Question-Answering"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&name=Dataset-for-Question-Answering&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://yuhangwuai.github.io/2024/08/14/Dataset-for-Question-Answering/&t=Dataset-for-Question-Answering"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2024
    YuhangWu
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/YuhangWuAI">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
